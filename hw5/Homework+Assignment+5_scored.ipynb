{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Monday November 5 12:59**, before the start of the lecture.\n",
    "\n",
    "Homework is in **groups of two**, and you are expected to hand in original work. Work that is copied from another group will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tharangni H Sivaji (11611065)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prettytable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b6d2284d6280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprettytable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrettyTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prettytable'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import diags\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Exercise 1\n",
    "Compute a solution to the equation\n",
    "\n",
    "$$ 600 x^4 - 550 x^3 + 200 x^2 - 20 x - 1 = 0, \\quad x \\in [0.1, 1.0], $$\n",
    "\n",
    "using each of the following methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = 600*x**4 - 550*x**3 + 200*x**2 - 20*x - 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_x(x):\n",
    "    y = 2400*x**3 - 1650*x**2 + 400*x -20\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Using the interval bisection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_bisection(a, b, tol):\n",
    "    \n",
    "    print(\"Interval Bisection: \\na: {}, b: {}\".format(a, b))\n",
    "\n",
    "    t = PrettyTable(['k', 'a', 'f(a)', 'b', 'f(b)'])\n",
    "    c = 0.0\n",
    "    k = np.ceil(np.log2((b-a)/tol))\n",
    "    data = {}\n",
    "\n",
    "    while((b-a) > tol):\n",
    "           \n",
    "        t.add_row([c, a, f(a), b, f(b)])\n",
    "        #data[c] = a\n",
    "        data[c] = b\n",
    "        m = a + (b-a)/2\n",
    "             \n",
    "        if (np.sign(f(a)) == np.sign(f(m))):\n",
    "            a = m\n",
    "        else:\n",
    "            b = m\n",
    "\n",
    "        c = c + 1\n",
    "    \n",
    "    print(t)\n",
    "    print(\"\\nNumber of iterations observed for tol {} is: {}\".format(tol, c))    \n",
    "    print(\"Number of iterations required for tol {} is: {}\".format(tol, k))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bisect = interval_bisection(0.1, 1.0, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Using newton's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(x0, tol):\n",
    "    \n",
    "    print(\"Newton method: \\nx0: {}\".format(x0))\n",
    "    t = PrettyTable(['k', 'x_k' ,'f(x_k)', 'f`(x_k) ', 'h_k'])\n",
    "    h_k = -f(x0)/f_x(x0)\n",
    "    k = 0\n",
    "    data = {}\n",
    "\n",
    "    while ( abs(f(x0)) > tol and abs(h_k)/abs(f(x0)) > tol ):\n",
    "        \n",
    "        h_k = -f(x0)/f_x(x0)\n",
    "        x1 = x0 + h_k\n",
    "\n",
    "        t.add_row([k, x0, f(x0), f_x(x0), h_k])\n",
    "        data[k] = x0\n",
    "\n",
    "        x0 = x1\n",
    "        k = k+1\n",
    "        \n",
    "    print(t)\n",
    "    print(\"\\nNumber of iterations required for tol {} is: {}\".format(tol, k))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newton = newton_method(1, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Using the secant method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant_method(x0, x1, tol):\n",
    "    \n",
    "    print(\"Secant method: \\nx0: {}, x1: {}\".format(x0, x1))\n",
    "    t = PrettyTable(['k', 'x_k' ,'f(x_k)', 'h_k'])\n",
    "    k = 0\n",
    "    h_k = 1\n",
    "    data = {}\n",
    "    \n",
    "    while ( abs(f(x1)) > tol ):\n",
    "        \n",
    "        h_k = - f(x1)*(x1 - x0)/(f(x1) - f(x0))\n",
    "        x2 = x1 + h_k\n",
    "        t.add_row([k, x1, f(x1), h_k])\n",
    "        data[k] = x1\n",
    "        \n",
    "        x0 = x1\n",
    "        x1 = x2\n",
    "        k = k+1\n",
    "        \n",
    "    print(t)\n",
    "    print(\"\\nNumber of iterations required for tol {} is: {}\".format(tol, k))    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secant = secant_method(3, 1, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)\n",
    "Compare the speed of convergence you observe for the three methods. Plot your results and briefly explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
    "plt.plot(bisect.keys(), bisect.values(), label = \"Interval Bisection\")\n",
    "plt.plot(len(bisect)-1, bisect[len(bisect)-1], \"b|\", markersize = 14, markeredgewidth = 2.5)\n",
    "plt.plot(newton.keys(), newton.values(), label = \"Newton Method\")\n",
    "plt.plot(len(newton)-1, newton[len(newton)-1], \"|\", color=\"orange\", markersize = 14, markeredgewidth = 2.5)\n",
    "plt.plot(secant.keys(), secant.values(), label = \"Secant Method\")\n",
    "plt.plot(len(secant)-1, secant[len(secant)-1], \"g|\", markersize = 14, markeredgewidth = 2.5)\n",
    "plt.xlabel(r'$k$ iterations', fontsize = 14)\n",
    "plt.ylabel(r'$x_k$ value at each iteration', fontsize = 14)\n",
    "plt.title(r'Speed of convergence for different methods', fontsize = 14)\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the three methods have the same starting point ($x_k = 1$) for uniform comparison. It can be seen that Newton method converges the fastest. Reasons for this are as follows:\n",
    "\n",
    "1. **Interval Bisection** : It takes the longest time to converge since it doesn't take the magnitude of the function value but rather only the sign for updating in the next iteration.\n",
    "2. **Newton Method** : It is so far the fastest method for convergence. It has a quaratic convergence rate. This means that the number of correct digits in the approximate solution is doubled at each iteration. \n",
    "3. **Secant Method** : The approximate solution produced by the secant method depends on the previous two iterates and thereby its convergence behaviour is somewhat complicated (hence a bit slower than Newton). It has a convergence rate of $\\approx 1.618$ and is superlinearly convergent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Fair conclusion. However, a semi-log-y plot of $k$ against $|f(x_k)|$ would've shown the quadratic convergence rate of Newton versus the linear convergence rate of the bisection method, which is something you can't really see right now. Minus 1/4 point.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# Exercise 2\n",
    "Consider the following boundary value problem involving a nonlinear ordinary differential equation:\n",
    "\n",
    "$$y''(x) + \\exp(y(x)) = 0, \\quad 0 < x < 1, \\quad y(0) = y(1) = 0.$$\n",
    "\n",
    "We can approximate the solution by discretizing the differential equation and solving the resulting system of nonlinear equations. Suppose we use $n+2$ discretization points for $x$ (denoted $x_k = kh$ for $k \\in \\{0, \\ldots, n+1\\}$ and $h = 1/(n+1)$, the approximate solution is denoted $y_k = y(x_k)$.\n",
    "\n",
    "We will use a _central finite difference_ approximation for the second derivative: \n",
    "\n",
    "$$y''(t_k) \\approx (y_{k+1} - 2 y_k + y_{k-1})/h^2.$$\n",
    "\n",
    "From the boundary values, we conclude that $y_0 = y_{n+1} = 0$. The result is a set of $n$ nonlinear equations\n",
    "\n",
    "$$ \\frac{y_{k+1} + y_{k-1} - 2 y_k}{h^2} + \\exp y_k = 0, \\quad k = 1, \\ldots, n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Write this set of equations as $\\mathbf{f}(\\mathbf x) = \\mathbf{0}$, where $\\mathbf f$ is a function from $\\mathbf x \\in \\mathbb R^{n}$ to $\\mathbf f(\\mathbf x) \\in \\mathbb R^{n}$. What is $\\mathbf x$, and what is $\\mathbf f$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x} = \n",
    "\\begin{bmatrix}\n",
    "y_1\\\\ \n",
    "y_2\\\\ \n",
    "\\vdots \\\\\n",
    "y_{n-1} \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "% \\begin{bmatrix}\n",
    "% 1\\\\ \n",
    "% 2\\\\ \n",
    "% \\vdots \\\\\n",
    "% {n-1} \\\\\n",
    "% n\n",
    "% \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From the equation given above,\n",
    "\n",
    "At k = 1, \n",
    "\n",
    "$y_2 + y_0 - 2y_1 + h^2 e^{y_1} = 0$\n",
    "\n",
    "$\\Rightarrow y_2 - 2y_1 + h^2 e^{y_1} = 0$\n",
    "\n",
    "At k = 2, \n",
    "\n",
    "$y_3 + y_1 - 2y_2 + h^2 e^{y_2} = 0$\n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "At k = n-1,\n",
    "\n",
    "$y_n + y_{n-2} - 2y_{n-1} + h^2 e^{y_{n-1}} = 0$\n",
    "\n",
    "At k = n,\n",
    "\n",
    "$y_{n+1} + y_{n-1} - 2y_{n} + h^2 e^{y_{n}} = 0$\n",
    "\n",
    "$\\Rightarrow y_{n-1} - 2y_{n} + h^2 e^{y_{n}} = 0$\n",
    "\n",
    "Taking only the co-efficents of these n equations to form the $\\mathbf{f}$ matrix,\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \n",
    "\\begin{bmatrix}\n",
    "-2y_1 +h^2 e^{y_1} & 1 & 0 & \\cdots & \\cdots & \\cdots & \\cdots\\\\ \n",
    "1 & -2y_2 +h^2 e^{y_2} & 1 & 0 & \\cdots & \\cdots & \\cdots\\\\ \n",
    "0 & 1 & -2y_3 +h^2 e^{y_3} & 1 & 0 & \\cdots & \\cdots\\\\ \n",
    "\\vdots & \\vdots  & \\ddots & \\ddots & \\ddots & \\cdots & \\cdots\\\\ \n",
    "\\vdots & \\vdots  & \\vdots & \\ddots & \\ddots & \\ddots & \\cdots \\\\ \n",
    "0 & 0 & 0 & \\cdots & 1 & -2y_{n-1} +h^2 e^{y_{n-1}} & 1\\\\ \n",
    "0 & 0 & 0 & \\cdots & 0 & 1 & -2y_{n} +h^2 e^{y_{n}} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ \\therefore \\mathbf{f(x)} = \n",
    "\\begin{bmatrix}\n",
    "f(x_1)\\\\ \n",
    "f(x_2)\\\\ \n",
    "\\vdots \\\\\n",
    "f(x_{n-1}) \\\\\n",
    "f(x_n)\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "y_2 - 2y_1 + h^2 e^{y_1}\\\\ \n",
    "y_3 + y_1 - 2y_2 + h^2 e^{y_2}\\\\ \n",
    "\\vdots \\\\ \n",
    "y_n + y_{n-2} - 2y_{n-1} + h^2 e^{y_{n-1}}\\\\ \n",
    " y_{n-1} - 2y_{n} + h^2 e^{y_{n}}\n",
    "\\end{bmatrix} = 0\n",
    "$$\n",
    "\n",
    "**NOTE:** From the above analysis, we get $n$ coupled equations which can be solved for the $n$ unknowns and the solution vector is given by $\\mathbf{f(x)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_vec(yk):\n",
    "    '''\n",
    "    The first and last indices have 0 value in order to account for y_0\n",
    "    and y_{n+1} = 0 conditions.\n",
    "    '''\n",
    "    \n",
    "    n = yk.shape[0]\n",
    "    print(n)\n",
    "    x = np.zeros((n+2, 1))\n",
    "    print(x)\n",
    "\n",
    "    for i in range(n+2):\n",
    "        if(i == n+1 or i == 0):\n",
    "            x[i] = 0\n",
    "        else:\n",
    "            x[i] = yk[i-1] \n",
    "    print(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "x = x_vec(np.array([0, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bvp_f(x):\n",
    "    '''\n",
    "    Returns f(x) vector as defined above\n",
    "    '''\n",
    "    \n",
    "    n = x.shape[0] - 2\n",
    "    h = 1/(n+1)\n",
    "    fx = np.zeros((n, 1))\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        y_kminus = x[i-1]\n",
    "        y_k = x[i]\n",
    "        y_kplus = x[i+1]\n",
    "        \n",
    "        fx[i-1] = y_kplus + y_kminus - 2*y_k + (h**2)*np.exp(y_k)\n",
    "    return fx/h**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bvp_f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "What is the Jacobian corresponding to this set of equations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{J} = \n",
    "\\begin{bmatrix}\n",
    "\\cfrac{\\partial f(x_1)}{\\partial x_1} & \\cdots & \\cdots & \\cfrac{\\partial f(x_1)}{\\partial x_n}\\\\ \n",
    "\\vdots & \\cdots & \\cdots & \\vdots\\\\  \n",
    "\\vdots & \\cdots & \\cdots & \\vdots\\\\ \n",
    "\\cfrac{\\partial f(x_n)}{\\partial x_1} & \\cdots & \\cdots & \\cfrac{\\partial f(x_n)}{\\partial x_n} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{J_f} = \n",
    "\\begin{bmatrix}\n",
    "-2 + h^2 e^{y_1} & 1 & 0 & \\cdots & \\cdots & \\cdots & 0\\\\ \n",
    "1 & -2 + h^2 e^{y_2} & 1 & 0 & \\cdots & \\cdots & 0\\\\ \n",
    "0 & 1 & -2 + h^2 e^{y_3} & 1  & 0 & \\cdots & 0\\\\ \n",
    "\\vdots & \\vdots  & \\ddots & \\ddots & \\ddots & \\cdots & \\vdots\\\\ \n",
    "\\vdots & \\vdots  & \\ddots & \\ddots & \\ddots & \\cdots & 0\\\\ \n",
    "0 & \\cdots & \\cdots & \\cdots & 1 & -2 + h^2 e^{y_{n-1}} & 1\\\\ \n",
    "0 & \\cdots & \\cdots & \\cdots & \\cdots & 1 & -2 + h^2 e^{y_n} \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bvp_J(x):\n",
    "    '''\n",
    "    Returns the jacobian matrix as defined above\n",
    "    '''\n",
    "    \n",
    "    n = x.shape[0] - 2\n",
    "    h = 1/(n+1)\n",
    "    main_dia = np.eye(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        y_k = x[i+1]\n",
    "        main_dia[i, i] = -2*y_k + (h**2)*np.exp(y_k)\n",
    "    \n",
    "    diagonals = [np.diagonal(main_dia), [1], [1]]\n",
    "    J = diags(diagonals, [0, 1, -1]).toarray()/h**2\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 25.,  0.,  0.],\n",
       "       [25.,  1., 25.,  0.],\n",
       "       [ 0., 25.,  1., 25.],\n",
       "       [ 0.,  0., 25.,  1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bvp_J(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Using Newton's method, solve the system of equations. Try various initial guesses, including zero (i.e., $y_k = 0$ for all $k$). Show the solutions you find, and discuss the convergence that you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_nonlinear(y_k, message = 1):\n",
    "    \n",
    "    k = 0\n",
    "    eps_mach = 2**-52 #overflow limit in machines\n",
    "    \n",
    "    k_list = []\n",
    "    \n",
    "    x0 = x_vec(y_k)\n",
    "    N = x0.shape[0]\n",
    "    f_norm = np.linalg.norm(bvp_f(x0), 2)\n",
    "    print(f_norm)\n",
    "    x1 = x0\n",
    "    while(abs(f_norm) > eps_mach/2 and k <= 100): #divide by 2 for further numerical stability (due to exp)\n",
    "\n",
    "        x = x0[1:N-1]\n",
    "        \n",
    "        k_list.append(k)\n",
    "        \n",
    "        f_x0 = bvp_f(x0)\n",
    "        J_x0 = bvp_J(x0)\n",
    "        \n",
    "        x1 = x - np.linalg.solve(J_x0, f_x0) \n",
    "        f_norm = np.linalg.norm(bvp_f(x1), 2)\n",
    "        \n",
    "        k = k+1\n",
    "        x0 = x_vec(x1)\n",
    "        \n",
    "    if(message):\n",
    "        print(\"Number of iterations taken for convergence with starting vector: {} is {}\".format(x_vec(y_k)[1:N-1].T, k))\n",
    "\n",
    "    return k_list, x1\n",
    "#     return k, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.898979485566356\n",
      "Number of iterations taken for convergence with starting vector: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] is 101\n",
      "880.131599691334\n",
      "Number of iterations taken for convergence with starting vector: [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]] is 101\n"
     ]
    }
   ],
   "source": [
    "m = 24\n",
    "k0, sol0 = newton_nonlinear(np.zeros((m,)), 1)\n",
    "k1, sol1 = newton_nonlinear(np.ones((m,)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-114.43451336],\n",
       "       [  11.74705224],\n",
       "       [ -64.1222741 ],\n",
       "       [ -92.22727193],\n",
       "       [ 108.56490731],\n",
       "       [-101.93805355],\n",
       "       [  11.89628018],\n",
       "       [-108.750562  ],\n",
       "       [  11.96186867],\n",
       "       [-117.78504899],\n",
       "       [  11.77714767],\n",
       "       [ -66.86397747],\n",
       "       [ -66.86397747],\n",
       "       [  11.77714767],\n",
       "       [-117.78504997],\n",
       "       [  11.96189268],\n",
       "       [-108.75649715],\n",
       "       [  11.98683774],\n",
       "       [-123.94451713],\n",
       "       [ 328.04473183],\n",
       "       [-116.27578575],\n",
       "       [ -61.63375875],\n",
       "       [  11.73442205],\n",
       "       [-114.43404448]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sol1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sol3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sol4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sort(sol6, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    m = 24\n",
    "    k1, sol1 = newton_nonlinear(np.ones((m,))*i, 0)\n",
    "    print(\"{}: Steps to converge: {}\".format(i, len(k1)))\n",
    "    n = sol1.shape[1] - 1\n",
    "    plt.plot(k1, sol1[:, n], label=\"y_k = {}s vector({} x {})\".format(i, m, 1))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Solution (x) at each iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol4[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    m = 24\n",
    "    \n",
    "    if(i==0):\n",
    "        k1, sol1 = newton_nonlinear(np.ones((m,))*i, 0)\n",
    "        n = sol1.shape[1] - 1\n",
    "        plt.plot(k1, sol1[:, n], label=\"y_k = {}s vector({} x {})\".format(i, m, 1))\n",
    "    else:\n",
    "        k1, sol1 = newton_nonlinear(np.random.randn(m,1), 0)\n",
    "        n = sol1.shape[1] - 1\n",
    "        plt.plot(k1, sol1[:, n], label=\"y_k = random vector({} x {})\".format(m, 1))\n",
    "    \n",
    "    print(\"{}: Steps to converge: {}\".format(i, len(k1)))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Solution (x) at each iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly initialising the starting vector doesn't tell anything about the convergence. \n",
    "\n",
    "However, 0 vectors ((24 x 1) vector filled with 0s), 1 vectors ((24 x 1) vector filled with 1s), 2 vectors ((24 x 1) vector filled with 2s) and so on, shed some light into the convergence behaviour. \n",
    "\n",
    "It is observed that varying the **vector size** greatly affects the convergence speed. Smaller vectors take a longer time to converge when compared to vectors of size > 10.\n",
    "\n",
    "Similarly, for different **vector size** different vectors (amongst 0, 1, 2, 3 ..) converge faster. For ex, amongst starting vectors of length 24, a vector initialised with all 2s converges the fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Your code seems alright, but you made a bunch of smallish errors which completely messed up your algorithm. First, `e_mach` should be $2^{-52}$, not $2^{52}$.. secondly, you missed a minus sign in the computation of the Jacobian (which surprised me, because you did it correctly in ex (b)..). These things together makes your code diverge. Minus 1.5 points.</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
