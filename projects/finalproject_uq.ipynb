{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Friday December 14, 10:59**, before the start of the lecture.\n",
    "\n",
    "The final project is in **groups of three**, and you are expected to hand in original work. Work that is copied from another group will not be accepted.\n",
    "\n",
    "A single, jointly written report for each group is fine. All members in a group will receive the same grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Project keywords\n",
    "Numerical integration, quadrature, interpolation, Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Project description\n",
    "Uncertainty quantification (UQ) is concerned with the question how the outcomes of a complex model or process are affected by uncertainty in the model input. Think of a model output $u$ that depends on an input parameter $x$. We can view $u$ as a function of $x$, so $u=u(x)$. In all kinds of applications (engineering, biology, climate, ..) it is not possible to characterize the function $u(x)$ easily because of the complexity of the model. Often, we only have a \"black box\" model available: we give it an input (value of $x$) and it returns an output, but we have no (or only limited) idea of what happens in between. Moreover, such models can be computationally very expensive, so that we cannot afford many model evaluations.\n",
    "\n",
    "A central question is: if we consider $x$ as a random input with a probability density function $f(x)$, what will be the probability distribution of the output $u(x)$? Can we estimate or approximate the lowest statistical moments of $u(x)$, such as its mean and variance? We define the raw (non-central) moments as\n",
    "$$\\mu_m = \\mathbb{E} (u(x))^m = \\int f(x) \\, (u(x))^m \\, dx  \\, , \\hspace{2cm} (*)$$\n",
    "so that $\\mu_1$ is the mean and $\\mu_2-\\mu_1^2$ is the variance.\n",
    "\n",
    "A straightforward way to estimate these moments is with the Monte Carlo (MC) method. However, with MC many samples are needed for accurate estimation, requiring many evaluations of the (expensive) model $u(x)$. The method of \\textit{Stochastic Collocation} (SC) can be an efficient alternative, enabling us to estimate the lowest moments with only a small number of $u(x)$ evaluations. Using SC we approximate the integral in (*) with an $N$-point quadrature rule, involving $N$ evaluations of $u(x)$. The accuracy of the approximation depends on the quadrature rule, the values of $N$ and $m$, and the smoothness of $u(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Project exercises\n",
    "## Exercise 1\n",
    "Read sections 7.3 and 8.3 from the book by Heath.\n",
    "\n",
    "## Exercise 2\n",
    "Focus on Gaussian quadrature rules and on the case where $x$ is one-dimensional (i.e., a single input parameter). If $u(x)$ were a polynomial of degree $k$, what should $N$ be in order to compute the $m$-th moment exactly using the $N$-point Gaussian quadrature rule?\n",
    "\n",
    "## Exercise 3\n",
    "Take $u(x)=\\tfrac12-\\exp(-\\tfrac12(x-3)^2)$ and assume that the probability distribution for $x$ is the uniform distribution on the interval $[0, 4]$, i.e. $x \\sim \\mathcal{U}[0,4]$.\n",
    "\n",
    "## Exercise 4\n",
    "Estimate the lowest three moments ($\\mu_1, \\mu_2, \\mu_3$) using the Monte Carlo method with e.g. 100 samples ($M=100$). Repeat the estimation 25 times (each time with different samples). Compute the mean and standard deviation of those 25 estimates to assess how accurate a single MC estimate is.\n",
    "\n",
    "## Exercise 5\n",
    "Pick a value of $N$, e.g. $N=9$, and determine the nodes and weights for the corresponding Gaussian quadrature rule (recall that $x\\sim \\mathcal{U}[0,4]$). The nodes are sometimes referred to as the collocation points.\n",
    "\n",
    "## Exercise 6\n",
    "Use Stochastic Collocation to compute (approximations) of $\\mu_1, \\mu_2, \\mu_3$ (i.e., use the $N$-point Gaussian quadrature rule).\n",
    "\n",
    "## Exercise 7\n",
    "Compare your SC results with the MC estimates. How many evaluations of $u(x)$ were used in each method?\n",
    "\n",
    "\n",
    "## Exercise 8\n",
    "Explore how the errors in the SC results and those in the MC results change if you vary the number of $u(x)$ evaluations involved. For computing errors you will need a \"benchmark\", if an exact (analytical) result is not feasible, a numerical approximation with high accuracy is a useful alternative. Discuss the results.\n",
    "\n",
    "## Exercise 9\n",
    "With the evaluations in the collocation points given, you can also construct an approximation $\\hat u(x)$ of the true output $u(x)$ using interpolation. Make a graph of $\\hat u (x)$ and $u(x)$ on the interval $x \\in [0,4]$, and assess the error of the approximation. What is a good way to quantify the error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
